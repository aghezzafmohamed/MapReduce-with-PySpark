{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setAppName(\"MapReduce with Spark\")\n",
    "#SparkContext : To initialize Spark\n",
    "sc = SparkContext.getOrCreate(conf=conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['now', 'we', 'will', 'decrease ', 'the', 'amount', 'of', 'data', 'that', 'is']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Open a textfile and return an RDD\n",
    "dataset = sc.textFile(\"inputs.txt\")\n",
    "dataset.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now', 1),\n",
       " ('we', 1),\n",
       " ('will', 1),\n",
       " ('decrease ', 1),\n",
       " ('the', 1),\n",
       " ('amount', 1),\n",
       " ('of', 1),\n",
       " ('data', 1),\n",
       " ('that', 1),\n",
       " ('is', 1)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply  a specific operation on every element in Spark RDD\n",
    "map_result = dataset.map(lambda x : (x,1))\n",
    "map_result.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['transferred', 'partitioner', 'optimisation', 'occurrences']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Apply filter operation on each element in Spark RDD\n",
    "filter_result = dataset.filter(lambda x: len(x)>10)\n",
    "filter_result.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GroupByKey operation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now', <pyspark.resultiterable.ResultIterable at 0x209d07c96a0>),\n",
       " ('we', <pyspark.resultiterable.ResultIterable at 0x209d07c9be0>),\n",
       " ('amount', <pyspark.resultiterable.ResultIterable at 0x209d07c9940>),\n",
       " ('of', <pyspark.resultiterable.ResultIterable at 0x209d07c9520>),\n",
       " ('is', <pyspark.resultiterable.ResultIterable at 0x209d07c9d00>),\n",
       " ('transferred', <pyspark.resultiterable.ResultIterable at 0x209d07c9a60>),\n",
       " ('nodes', <pyspark.resultiterable.ResultIterable at 0x209d07c9a00>),\n",
       " ('combiner', <pyspark.resultiterable.ResultIterable at 0x209d07c9ee0>),\n",
       " ('thought', <pyspark.resultiterable.ResultIterable at 0x209d07c98e0>),\n",
       " ('as', <pyspark.resultiterable.ResultIterable at 0x209d07c9bb0>)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Group the elements by key in Spark RDD\n",
    "groupByKey_result = map_result.groupByKey()\n",
    "groupByKey_result.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ReduceByKey operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('now', 1),\n",
       " ('we', 1),\n",
       " ('amount', 1),\n",
       " ('of', 3),\n",
       " ('is', 3),\n",
       " ('transferred', 1),\n",
       " ('nodes', 1),\n",
       " ('combiner', 7),\n",
       " ('thought', 1),\n",
       " ('as', 3)]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Reduce the elements by key in Spark RDD\n",
    "reduceByKey_result = map_result.reduceByKey(lambda a, b: a + b)\n",
    "reduceByKey_result.take(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SortByKey operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hadoop', 1),\n",
       " ('a', 1),\n",
       " ('a', 1),\n",
       " ('a', 1),\n",
       " ('a', 1),\n",
       " ('a', 1),\n",
       " ('adding', 1),\n",
       " ('amount', 1),\n",
       " ('an', 1),\n",
       " ('and', 1)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Sort the elements by key in Spark RDD\n",
    "sortByKey_result = map_result.sortByKey()\n",
    "sortByKey_result.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of elements in an RDD is :107\n"
     ]
    }
   ],
   "source": [
    "#Return the number of element in Spark RDD\n",
    "number_element = map_result.count()\n",
    "print(\"The number of elements in an RDD is :\"+ str(number_element))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
